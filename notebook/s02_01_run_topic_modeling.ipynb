{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Pre-setting\n",
    "# automatically adjust the width of the notebook code cell\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# if one module is changed, this line will automatically reload that module\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# display the figure in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# To change the font size in acrobat\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Add path\n",
    "import os\n",
    "import sys\n",
    "src_dir = os.path.abspath(os.path.join(os.pardir, 'src'))\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.insert(0, src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Private package\n",
    "\n",
    "from corpora.pp_single_stopword import synthetic_single_stopword_terminal\n",
    "\n",
    "from models.modelfront import topicmodel_inference_front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# creat synthetic benchmark data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Parameters for distribution\n",
    "\n",
    "V = 400 # nubmer of words\n",
    "K = 5 # nubmer of topics\n",
    "\n",
    "dist_w = 'uni'  # global word frequency. uni or zipf\n",
    "# dist_t = dist_w # number of words in each topic. uni or zipf\n",
    "\n",
    "dist_stop = 'uni' # probability of stopwords appearance.\n",
    "p_s = 0.1 # 100 * p_s is the percentage of the stopword \n",
    "\n",
    "c_w = 0.8  # degree of structure for word mixing for each topic. 0: random; 1: structure\n",
    "# c_t = c_w # degree of structure for topic mixing for each document. 0: random; 1: structure\n",
    "\n",
    "## Parameters for document\n",
    "\n",
    "D = 2000 # nubmer of document\n",
    "m = 100 # length of document\n",
    "\n",
    "\n",
    "## Parameters for random function\n",
    "seed = 5\n",
    "burstiness = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.19 s, sys: 48.8 ms, total: 2.24 s\n",
      "Wall time: 2.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dict_out_syn_stop = synthetic_single_stopword_terminal(V = V , K = K, D = D, m = m, dist_w =dist_w, dist_stop = dist_stop, p_s = p_s, c_w = c_w, seed = seed, burstiness = burstiness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['V_t', 'p_wt', 'p_t', 'n_wj', 'p_td', 'word_topic_assign_list', 'n_jd', 'p_w_td', 'p_w', 'document_topic_assign_list', 'n_wd', 'texts', 'state_dwz'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_out_syn_stop.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,\n",
       " ['6',\n",
       "  '9',\n",
       "  '17',\n",
       "  '18',\n",
       "  '18',\n",
       "  '18',\n",
       "  '33',\n",
       "  '33',\n",
       "  '37',\n",
       "  '42',\n",
       "  '48',\n",
       "  '49',\n",
       "  '50',\n",
       "  '53',\n",
       "  '57',\n",
       "  '74',\n",
       "  '75',\n",
       "  '89',\n",
       "  '89',\n",
       "  '94'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of the first document\n",
    "len(dict_out_syn_stop['texts'][0]), dict_out_syn_stop['texts'][0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = dict_out_syn_stop['texts']\n",
    "state_dwz = dict_out_syn_stop['state_dwz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run different topic modeling algorithms on synthetic benchmark corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that for the synthetic benchmark corpus, since we have the true topic assignment of each token, we will use this token topic assignment as an input for topic modeling. And in this case, we put together topic inference and the structure overlap measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run topic model: ldavb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "dict_input_ldavb = {\n",
    "    \n",
    "    ## choose topic model\n",
    "    'topic_model': 'ldavb'\n",
    "    \n",
    "    ## provide corpus and number of topics if need\n",
    "    , 'texts':texts\n",
    "    , 'input_k': K\n",
    "\n",
    "    ## optional, only works for synthetic corpus with token labeling\n",
    "    , 'state_dwz_true': state_dwz\n",
    "    , 'k_true': K \n",
    "    , 'input_v': V  # only need for ldavb- token labeling\n",
    "    \n",
    "    ## optional\n",
    "    , 'dN_opt':0 ## optional\n",
    "    , 'minimum_probability':0 ## optional   \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.9 s, sys: 309 ms, total: 21.2 s\n",
      "Wall time: 21.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dict_output_ldavb = topicmodel_inference_front( dict_input_ldavb )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['token_labeling_model_nmi', 'token_labeling_perfect_nmi', 'state_dwz_infer', 'p_wt_infer', 'token_labeling_rand_nmi', 'token_labeling_normal_nmi', 'p_td_infer'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_output_ldavb.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00202538,  0.97245211,  0.00201647,  0.00203503,  0.021471  ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_output_ldavb['p_td_infer'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.384272764544\n"
     ]
    }
   ],
   "source": [
    "token_labeling_model_nmi = dict_output_ldavb.get('token_labeling_model_nmi', None)\n",
    "print(token_labeling_model_nmi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run topic model: ldavb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_input_ldags = {\n",
    "    ## choose topic model\n",
    "    'topic_model': 'ldags'\n",
    "    \n",
    "    ## provide corpus and number of topics if need\n",
    "    , 'texts':texts\n",
    "    , 'input_k': K # only for ldavb and ladgs\n",
    "    \n",
    "    ## optional, only works for synthetic corpus with token labeling\n",
    "    , 'state_dwz_true': state_dwz\n",
    "    , 'k_true': K \n",
    "\n",
    "    \n",
    "#     ## optional\n",
    "#     , 'input_v': V  # only need for ldavb token labeling\n",
    "#     , 'path_mallet': os.path.abspath(os.path.join(os.pardir,'src/external/mallet-2.0.8RC3/bin/mallet')) \n",
    "#     , 'dN_opt':0 \n",
    "#     , 'N_iter':1000 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hanyushi/projects/s11_synthetic_benchmark_topic_model_tutorial/tmp\n",
      "CPU times: user 8.88 s, sys: 217 ms, total: 9.09 s\n",
      "Wall time: 28.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# in order to run ldags, we need to create a folder 'tmp' to save the intermediate files generated during the inference process\n",
    "path_tmp_file  = os.path.abspath(os.path.join(os.pardir,'tmp'))\n",
    "print(path_tmp_file)\n",
    "if not os.path.exists(path_tmp_file):\n",
    "    os.makedirs(path_tmp_file)\n",
    "\n",
    "\n",
    "dict_output_ldags = topicmodel_inference_front( dict_input_ldags )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['token_labeling_perfect_nmi', 'token_labeling_model_nmi', 'p_wt_infer', 'token_labeling_rand_nmi', 'state_dwz_infer', 'token_labeling_normal_nmi', 'p_td_infer'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_output_ldags.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1       ,  0.54666667,  0.12666667,  0.12      ,  0.10666667])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_output_ldags['p_td_infer'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.515504183298\n"
     ]
    }
   ],
   "source": [
    "token_labeling_model_nmi = dict_output_ldags.get('token_labeling_model_nmi', None)\n",
    "print(token_labeling_model_nmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run topic model: hdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_input_hdp = {\n",
    "    ## choose topic model\n",
    "    'topic_model': 'hdp'\n",
    "\n",
    "    ## provide corpus and number of topics if need\n",
    "    , 'texts':texts\n",
    "\n",
    "    ## optional, only works for synthetic corpus with token labeling\n",
    "    , 'state_dwz_true': state_dwz\n",
    "    , 'k_true': K \n",
    "\n",
    "\n",
    "    ## optional\n",
    "#     , 'path_hdp': os.path.abspath(os.path.join(os.pardir,'src/external/hdp-bleilab/hdp-faster'))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.33 s, sys: 157 ms, total: 6.49 s\n",
      "Wall time: 16.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dict_output_hdp = topicmodel_inference_front( dict_input_hdp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['k_infer', 'token_labeling_normal_nmi', 'token_labeling_model_nmi', 'p_td_infer', 'token_labeling_perfect_nmi', 'state_dwz_infer', 'p_wt_infer', 'token_labeling_rand_nmi'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_output_hdp.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.22,  0.01,  0.11,  0.56,  0.  ,  0.1 ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_output_hdp['p_td_infer'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.455796473424\n"
     ]
    }
   ],
   "source": [
    "token_labeling_model_nmi = dict_output_hdp.get('token_labeling_model_nmi', None)\n",
    "print(token_labeling_model_nmi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_output_hdp['k_infer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run topic model: tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_input_tm = {\n",
    "    ## choose topic model\n",
    "    'topic_model': 'tm'\n",
    "\n",
    "    ## provide corpus and number of topics if need\n",
    "    , 'texts':texts\n",
    "\n",
    "    ## optional, only works for synthetic corpus with token labeling\n",
    "    , 'state_dwz_true': state_dwz\n",
    "    , 'k_true': K \n",
    "\n",
    "\n",
    "    ## optional\n",
    "    , 'path_tm': os.path.abspath(os.path.join(os.pardir,'src/external/topicmapping'))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.78 s, sys: 184 ms, total: 6.96 s\n",
      "Wall time: 28.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dict_output_tm = topicmodel_inference_front( dict_input_tm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['k_infer', 'token_labeling_normal_nmi', 'token_labeling_model_nmi', 'p_td_infer', 'token_labeling_perfect_nmi', 'state_dwz_infer', 'p_wt_infer', 'token_labeling_rand_nmi'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_output_tm.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.98886161e-01,   2.78407151e-04,   2.82944683e-04,\n",
       "         2.72788160e-04,   2.79699309e-04])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_output_tm['p_td_infer'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.591038354937\n"
     ]
    }
   ],
   "source": [
    "token_labeling_model_nmi = dict_output_tm.get('token_labeling_model_nmi', None)\n",
    "print(token_labeling_model_nmi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_output_tm['k_infer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
